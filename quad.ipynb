{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import yfinance as yf\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Data:\n",
    "    def __init__(self):\n",
    "        self.data = yf.download('AAPL', period='5y', interval='1d')\n",
    "        self.current_index = 0\n",
    "\n",
    "    def get_current_price(self):\n",
    "        if self.current_index < len(self.data):\n",
    "            return self.data.iloc[self.current_index]['Close']\n",
    "        else:\n",
    "            return None\n",
    "\n",
    "    def get_tensor(self):\n",
    "        end_index = self.current_index + 1\n",
    "        start_index = max(0, end_index - 15)\n",
    "        return np.array(self.data.iloc[start_index:end_index])\n",
    "\n",
    "    def next(self):\n",
    "        if self.current_index < len(self.data) - 1:\n",
    "            self.current_index += 1\n",
    "        else:\n",
    "            self.current_index = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Brain:\n",
    "    def __init__(self):\n",
    "        self.model = tf.keras.Sequential()\n",
    "        initializer = tf.keras.initializers.RandomUniform(minval=-.5, maxval=.5, seed=42)\n",
    "        # Define a model with 10 output neurons corresponding to binary classification tasks\n",
    "        self.model.add(tf.keras.layers.Dense(80, activation='relu', input_shape=(75,), kernel_initializer=initializer))\n",
    "        self.model.add(tf.keras.layers.Dense(10, activation='sigmoid', kernel_initializer=initializer))\n",
    "        self.model.compile(loss='mse', optimizer='adam', metrics=['accuracy', 'mse'])\n",
    "\n",
    "    def prediction(self, inputs):\n",
    "\n",
    "        inputs_np = np.array(inputs).reshape(1, -1)\n",
    "        pred = self.model.predict(inputs_np, verbose=0)\n",
    "\n",
    "        binary_outputs = (pred >= 0.5).astype(int)\n",
    "        \n",
    "        x, y = binary_outputs[0, 0], binary_outputs[0, 1]\n",
    "\n",
    "        binary_string = ''.join(str(bit) for bit in binary_outputs[0, 2:])\n",
    "        decimal_value = int(binary_string, 2)\n",
    "\n",
    "        z = decimal_value / 255\n",
    "\n",
    "        return [x, y, z]\n",
    "\n",
    "    def set_weights(self, weights):\n",
    "        self.model.set_weights(weights)\n",
    "\n",
    "    def get_weights(self):\n",
    "        return self.model.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    }
   ],
   "source": [
    "class Agent:\n",
    "\n",
    "    data = Data()\n",
    "    id = 0\n",
    "\n",
    "    def __init__(self):\n",
    "        self.id = Agent.id\n",
    "        Agent.id = Agent.id + 1\n",
    "        self.returns = 0\n",
    "        self.fitness = 0\n",
    "        self.input_dimension = 75\n",
    "        self.row_dimension = 5\n",
    "        self.row_data = Agent.data.get_tensor()[0] # numpy array of length 6\n",
    "\n",
    "        temp = []\n",
    "        for i in range(self.row_dimension):\n",
    "            temp.append(self.row_data[i])\n",
    "        for _ in range(self.input_dimension - self.row_dimension):\n",
    "            temp.append(0)\n",
    "\n",
    "        self.inputs = temp # python list of length 75\n",
    "        self.current_price = self.inputs[0]\n",
    "        self.brain = Brain()\n",
    "        self.predictions = self.brain.prediction(self.inputs) # returns [{0, 1}, {0, 1}, float_between(0, 1)]\n",
    "        self.active_trades = []\n",
    "\n",
    "    def __lt__(self, other):\n",
    "        if self.returns < other.returns:\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "\n",
    "    def make_trades(self):\n",
    "        if self.predictions[0] > 0.5:\n",
    "            if self.predictions[1] > 0.5:\n",
    "                self.buy(self.current_price * (1 + self.predictions[2]))\n",
    "            else:\n",
    "                self.sell(self.current_price * (1 - self.predictions[2]))\n",
    "\n",
    "    def buy(self, target):\n",
    "        if target > self.inputs[0] * 1.10:\n",
    "            self.fitness -= 10\n",
    "        else:\n",
    "            self.active_trades.append([target, 2*self.current_price - target, target - self.current_price, 1])\n",
    "\n",
    "    def sell(self, target):\n",
    "        if target < self.inputs[0] * 0.9:\n",
    "            self.fitness -= 10\n",
    "        else:\n",
    "            self.active_trades.append([target, 2*self.current_price - target, self.current_price - target, 0])\n",
    "\n",
    "    def close_trades(self):\n",
    "        to_keep = []\n",
    "        # print(f\"Active Trades: {self.active_trades}\")\n",
    "        for trade in self.active_trades:\n",
    "            if trade[3] == 1:\n",
    "                if trade[0] <= self.current_price:\n",
    "                    self.returns += trade[2]\n",
    "                elif trade[1] >= self.current_price:\n",
    "                    self.returns -= trade[2]\n",
    "                else:\n",
    "                    to_keep.append(trade)\n",
    "            else:\n",
    "                if trade[0] >= self.current_price:\n",
    "                    self.returns += trade[2]\n",
    "                elif trade[1] <= self.current_price:\n",
    "                    self.returns -= trade[2]\n",
    "                else:\n",
    "                    to_keep.append(trade)\n",
    "        self.active_trades = to_keep\n",
    "        # print(f\"Active Trades: {self.active_trades}\")\n",
    "\n",
    "    def force_close_trades(self):\n",
    "        clear = []\n",
    "        for trade in self.active_trades:\n",
    "            open = (trade[0] + trade[1]) / 2\n",
    "            if trade[3] == 1:\n",
    "                self.returns += self.current_price - open\n",
    "            else:\n",
    "                self.returns += open - self.current_price\n",
    "        self.active_trades = clear\n",
    "\n",
    "    def get_next_inputs(self):\n",
    "    # goes to next day, and appends the new data to inputs\n",
    "        self.data.next()\n",
    "        self.row_data = Agent.data.get_tensor()[0]\n",
    "        for i in range(self.row_dimension):\n",
    "            self.inputs.insert(0, self.row_data[i])\n",
    "            self.inputs.pop()\n",
    "        self.current_price = self.inputs[0]\n",
    "        self.predictions = self.brain.prediction(self.inputs)\n",
    "\n",
    "    def cycle(self):\n",
    "        self.close_trades()\n",
    "        self.make_trades()\n",
    "        self.get_next_inputs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Gen:\n",
    "    def __init__(self, population_size, generations, mutation_rate=0.1):\n",
    "        self.population_size = population_size\n",
    "        self.generations = generations\n",
    "        self.mutation_rate = mutation_rate\n",
    "\n",
    "    def crossover(self, parent1, parent2):\n",
    "        child = Agent()\n",
    "        p1_weights = parent1.brain.get_weights()\n",
    "        p2_weights = parent2.brain.get_weights()\n",
    "        new_weights = []\n",
    "    \n",
    "        for p1_layer, p2_layer in zip(p1_weights, p2_weights):\n",
    "            if len(p1_layer.shape) == 1:  # This means the layer is one-dimensional (biases)\n",
    "                gene_cutoff = np.random.randint(0, p1_layer.size)\n",
    "                new_gene = np.concatenate([p1_layer[:gene_cutoff], p2_layer[gene_cutoff:]])\n",
    "            else:  # This means the layer is two-dimensional (weights)\n",
    "                gene_cutoff = np.random.randint(0, p1_layer.size)\n",
    "                new_gene = np.concatenate([p1_layer[:gene_cutoff], p2_layer[gene_cutoff:]])\n",
    "    \n",
    "            new_weights.append(new_gene)\n",
    "\n",
    "        child.brain.set_weights(new_weights)\n",
    "        return child\n",
    "    \n",
    "    def mutate(self, agent):\n",
    "        weights = agent.brain.get_weights()\n",
    "        mutated_weights = []\n",
    "        for weight in weights:\n",
    "            if np.random.rand() < self.mutation_rate:\n",
    "                mutation_matrix = np.random.uniform(-0.1, 0.1, weight.shape)\n",
    "                weight += mutation_matrix\n",
    "            mutated_weights.append(weight)\n",
    "        agent.brain.set_weights(mutated_weights)\n",
    "\n",
    "    def simulate(self):\n",
    "        agents = []\n",
    "        for _ in range(self.population_size):\n",
    "            agent = Agent()\n",
    "            agents.append(agent)\n",
    "        for generation in range(self.generations):\n",
    "            for agent in agents:\n",
    "                for i in range(50):\n",
    "                    agent.cycle()\n",
    "                agent.force_close_trades()\n",
    "                print(f\"Agent {agent.id}'s returns after {i + 1} cycles: {agent.returns}\")\n",
    "            ranked_agents = sorted(agents)\n",
    "            ranked_agents.reverse()\n",
    "            print(f\"=== Gen {generation} ===\\n Best: ${ranked_agents[0].returns}. Worst: ${ranked_agents[-1].returns}\")\n",
    "\n",
    "            elites = ranked_agents[:len(ranked_agents) // 2]\n",
    "            new_generation = []\n",
    "            for _ in range(int(self.population_size * 0.8)):\n",
    "                child = self.crossover(random.choice(elites), random.choice(elites))\n",
    "                self.mutate(child)\n",
    "                new_generation.append(child)\n",
    "            for i in range(int(self.population_size * 0.2)):\n",
    "                new_generation.append(elites[i])\n",
    "\n",
    "            agents = new_generation\n",
    "        return ranked_agents[0].brain.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 305 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f3c503d09d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Agent 0's returns after 50 cycles: 12.48332887537341\n",
      "Agent 1's returns after 50 cycles: -20.25189255359127\n",
      "Agent 2's returns after 50 cycles: -93.3046607223211\n",
      "Agent 3's returns after 50 cycles: -110.6268691717409\n",
      "=== Gen 0 ===\n",
      " Best: $12.48332887537341. Worst: $-110.6268691717409\n",
      "Agent 4's returns after 50 cycles: 37.20886686736457\n",
      "Agent 5's returns after 50 cycles: -123.55762433818728\n",
      "Agent 6's returns after 50 cycles: -134.12956195906088\n",
      "=== Gen 1 ===\n",
      " Best: $37.20886686736457. Worst: $-134.12956195906088\n",
      "Agent 7's returns after 50 cycles: -30.489920373056478\n",
      "Agent 8's returns after 50 cycles: -140.97755815094578\n",
      "Agent 9's returns after 50 cycles: -15.49586660347731\n",
      "=== Gen 2 ===\n",
      " Best: $-15.49586660347731. Worst: $-140.97755815094578\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([[-0.16761781,  0.05688417,  0.30791163, ..., -0.09788541,\n",
       "          0.46356633, -0.38815358],\n",
       "        [-0.07774486, -0.27795413, -0.34551874, ..., -0.4228381 ,\n",
       "          0.02580727, -0.3053085 ],\n",
       "        [-0.20599912, -0.2602686 , -0.54277766, ..., -0.2237016 ,\n",
       "         -0.02388559,  0.3675535 ],\n",
       "        ...,\n",
       "        [ 0.44976693, -0.41277543,  0.3877659 , ...,  0.313583  ,\n",
       "         -0.3625246 , -0.08648679],\n",
       "        [ 0.43188724,  0.45396322, -0.20409885, ..., -0.217931  ,\n",
       "          0.21105018, -0.2958902 ],\n",
       "        [-0.32676   ,  0.24652857,  0.5357856 , ...,  0.04376383,\n",
       "          0.23130421,  0.44235197]], dtype=float32),\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32),\n",
       " array([[-2.17566848e-01, -1.58309937e-03,  2.15458512e-01,\n",
       "         -4.79797959e-01, -4.21401858e-01,  1.26559377e-01,\n",
       "          2.54998326e-01, -3.26794147e-01, -3.71287346e-01,\n",
       "         -4.47329521e-01],\n",
       "        [ 4.42529202e-01, -2.69548059e-01, -2.24584341e-02,\n",
       "         -2.53444910e-01,  2.24575996e-01,  2.69065857e-01,\n",
       "          3.69108915e-02, -3.31294894e-01,  2.80845165e-03,\n",
       "         -3.00057411e-01],\n",
       "        [-4.64703083e-01, -1.87219620e-01, -2.56056786e-02,\n",
       "          5.97994328e-02,  3.23537230e-01,  9.13666487e-02,\n",
       "         -1.79730654e-01,  2.62521386e-01, -3.74247432e-01,\n",
       "          9.80285406e-02],\n",
       "        [-1.97220445e-01,  3.52858901e-01,  4.48628426e-01,\n",
       "          2.60492563e-01, -1.85151935e-01,  1.69372916e-01,\n",
       "          4.13738489e-02,  4.92382407e-01,  1.43612862e-01,\n",
       "         -4.83288169e-01],\n",
       "        [ 8.91736746e-02,  1.92196131e-01,  3.58860493e-01,\n",
       "          3.30715418e-01,  4.05372977e-01,  3.08267832e-01,\n",
       "          4.03654695e-01, -4.90951657e-01,  2.67178178e-01,\n",
       "         -4.92082596e-01],\n",
       "        [ 3.12481642e-01, -3.07811856e-01, -4.23606038e-01,\n",
       "         -2.61145949e-01, -9.02746916e-02,  3.26433539e-01,\n",
       "          1.14559174e-01, -2.84583449e-01, -3.77620816e-01,\n",
       "          3.43938947e-01],\n",
       "        [-2.14065313e-01,  3.86576772e-01, -3.55095029e-01,\n",
       "          4.97509837e-01,  8.10357332e-02, -3.08075070e-01,\n",
       "          5.04231453e-02,  4.69853878e-02, -3.07155728e-01,\n",
       "         -2.49023199e-01],\n",
       "        [-1.18499160e-01,  4.38233972e-01,  1.48274064e-01,\n",
       "         -2.08305597e-01, -4.53543663e-02, -1.99659109e-01,\n",
       "         -1.13038540e-01,  3.26633453e-04,  4.44479227e-01,\n",
       "         -3.37134957e-01],\n",
       "        [-9.48520899e-02, -2.77611017e-01, -2.70486355e-01,\n",
       "          2.32547998e-01,  3.06820869e-02, -1.39692068e-01,\n",
       "         -3.87148857e-01,  1.46786451e-01, -1.30283117e-01,\n",
       "         -2.00068951e-02],\n",
       "        [ 3.41388583e-01, -4.98183966e-01, -2.13198900e-01,\n",
       "          8.07253122e-02,  1.75009727e-01,  1.19205713e-02,\n",
       "         -1.95000768e-01,  3.19698572e-01,  7.39456415e-02,\n",
       "         -2.87669659e-01],\n",
       "        [-4.75714803e-01, -4.69553947e-01, -3.45160246e-01,\n",
       "         -2.45424151e-01,  3.68144393e-01,  1.89559102e-01,\n",
       "          2.50416994e-01,  2.44459987e-01, -4.47954655e-01,\n",
       "         -1.67210579e-01],\n",
       "        [ 1.54439330e-01, -1.78523779e-01, -1.39902830e-02,\n",
       "          4.64007378e-01, -4.02626991e-02, -4.70761895e-01,\n",
       "         -3.13098907e-01,  2.09701896e-01,  2.17120171e-01,\n",
       "          3.46404791e-01],\n",
       "        [ 1.10641479e-01,  3.70225549e-01, -6.86774254e-02,\n",
       "         -3.36959362e-02, -3.33679914e-01,  3.07364821e-01,\n",
       "          9.68360901e-03, -1.15290880e-02, -2.11157322e-01,\n",
       "          4.94057894e-01],\n",
       "        [ 4.73052979e-01, -3.45913410e-01, -4.84765172e-01,\n",
       "          2.78252482e-01, -2.93010712e-01,  2.21979022e-01,\n",
       "          7.31457472e-02, -4.77203608e-01,  4.52910185e-01,\n",
       "          5.24522066e-02],\n",
       "        [ 2.16374397e-02, -2.19255209e-01, -4.25082445e-02,\n",
       "         -4.91667986e-01, -2.84088731e-01,  2.49357224e-01,\n",
       "          4.08947587e-01, -1.14394069e-01,  1.14160180e-01,\n",
       "          1.68746591e-01],\n",
       "        [ 3.34764719e-01,  1.18920684e-01,  2.31597662e-01,\n",
       "          3.06867242e-01, -1.04034901e-01, -3.02153945e-01,\n",
       "         -1.02928877e-02, -4.49580669e-01,  5.38349152e-04,\n",
       "         -2.12531567e-01],\n",
       "        [-2.65138865e-01, -2.40876913e-01, -4.64364529e-01,\n",
       "          2.30512261e-01,  9.92513895e-02,  4.52469826e-01,\n",
       "         -3.52934480e-01, -3.42056990e-01,  3.76772046e-01,\n",
       "         -2.19985127e-01],\n",
       "        [-3.27339053e-01, -2.20300555e-01,  1.18804097e-01,\n",
       "         -2.90686369e-01, -9.63032246e-02, -3.73528361e-01,\n",
       "         -4.48964953e-01, -9.03065205e-02,  4.91985798e-01,\n",
       "         -4.79075193e-01],\n",
       "        [-1.27024412e-01, -4.12597179e-01, -2.63794541e-01,\n",
       "          3.07572365e-01,  3.66430521e-01, -4.97947454e-01,\n",
       "          4.82055783e-01, -1.38775587e-01, -1.54862404e-02,\n",
       "         -2.94660330e-01],\n",
       "        [-3.96049023e-03, -4.71625328e-02,  2.46882319e-01,\n",
       "         -2.97839046e-01, -1.90865993e-01,  3.23710799e-01,\n",
       "          1.79501891e-01,  4.58847284e-02, -1.54949546e-01,\n",
       "         -1.07397795e-01],\n",
       "        [ 3.62946272e-01, -1.51174068e-02, -6.21168613e-02,\n",
       "          4.41733360e-01,  4.04146314e-01, -3.48056793e-01,\n",
       "          4.00914192e-01, -2.53987312e-03,  2.26264000e-01,\n",
       "         -6.25383854e-02],\n",
       "        [ 4.76742625e-01, -1.05561137e-01,  3.91703844e-01,\n",
       "          4.96343493e-01,  6.16337061e-02,  3.35083246e-01,\n",
       "          4.99346852e-01, -4.14052606e-01, -9.28131342e-02,\n",
       "         -4.23964500e-01],\n",
       "        [ 4.96974111e-01,  4.29093957e-01, -9.03022289e-03,\n",
       "          4.48827744e-02,  5.40999174e-02,  1.65922761e-01,\n",
       "          7.83725977e-02,  2.48850822e-01, -2.11654425e-01,\n",
       "         -1.73488855e-01],\n",
       "        [ 4.65600371e-01, -4.90393877e-01,  2.68661737e-01,\n",
       "         -1.01466537e-01,  2.29466319e-01,  1.34089470e-01,\n",
       "         -4.80557203e-01, -2.67143846e-01, -3.95858288e-02,\n",
       "          2.94577956e-01],\n",
       "        [ 5.19217253e-02,  1.62864685e-01,  4.26784873e-01,\n",
       "         -3.65963459e-01, -1.50542021e-01, -4.50543404e-01,\n",
       "         -2.29088783e-01, -3.73096347e-01,  2.92199731e-01,\n",
       "          3.25020552e-02],\n",
       "        [ 3.36118698e-01, -3.53269100e-01,  2.88523436e-01,\n",
       "         -3.07638526e-01, -4.26760077e-01,  4.57227945e-01,\n",
       "          3.41889024e-01, -3.58949900e-02, -2.30284929e-02,\n",
       "         -6.74163103e-02],\n",
       "        [ 3.81294727e-01, -4.27250266e-01, -2.48512149e-01,\n",
       "         -2.10965276e-01, -4.74367380e-01, -1.69732213e-01,\n",
       "         -1.53110147e-01, -1.33590937e-01, -1.24401689e-01,\n",
       "          9.63442326e-02],\n",
       "        [-1.11592293e-01, -4.61016655e-01, -4.67187166e-01,\n",
       "          4.34945464e-01,  4.46742177e-01,  2.13919997e-01,\n",
       "         -3.21670175e-01, -4.39733505e-01, -1.46460533e-03,\n",
       "          4.04625416e-01],\n",
       "        [ 4.37007904e-01,  3.18505764e-02,  4.57471609e-02,\n",
       "          2.10387588e-01, -4.48693991e-01, -2.96251178e-01,\n",
       "          1.22488379e-01,  9.22461748e-02, -3.95136356e-01,\n",
       "          3.94612789e-01],\n",
       "        [ 8.60183239e-02,  2.11552262e-01, -4.37234879e-01,\n",
       "          3.20121050e-02,  3.22273254e-01, -3.70674968e-01,\n",
       "          2.10186005e-01, -6.64124489e-02, -1.49276972e-01,\n",
       "         -2.02067614e-01],\n",
       "        [-3.37103009e-01, -2.98875928e-01,  2.22483039e-01,\n",
       "          1.03900075e-01,  3.75718474e-01, -3.68900418e-01,\n",
       "         -4.82693195e-01, -3.69542599e-01, -4.81220603e-01,\n",
       "         -1.92113280e-01],\n",
       "        [ 1.93987012e-01, -1.99504256e-01,  3.52660179e-01,\n",
       "          2.07728863e-01,  1.76995397e-01,  1.12185001e-01,\n",
       "         -4.51225638e-01, -3.88525844e-01,  4.91056323e-01,\n",
       "          2.53028631e-01],\n",
       "        [ 3.02632689e-01, -1.59861088e-01, -4.68756676e-01,\n",
       "         -3.48607779e-01, -1.93534732e-01, -3.06111574e-01,\n",
       "          1.03813529e-01,  4.31382775e-01,  4.03791189e-01,\n",
       "          2.54648924e-01],\n",
       "        [ 2.34879971e-01, -8.62264633e-02, -4.65271592e-01,\n",
       "         -3.32496643e-01,  1.39333010e-02, -4.36610937e-01,\n",
       "         -4.29769516e-01,  1.69889212e-01, -9.25593376e-02,\n",
       "         -1.53460383e-01],\n",
       "        [-3.57361436e-01,  4.85985279e-02, -6.68243170e-02,\n",
       "         -1.65733099e-01,  6.39317036e-02, -2.91381836e-01,\n",
       "          1.78990245e-01,  4.98483896e-01,  1.37174368e-01,\n",
       "          4.39632535e-01],\n",
       "        [ 3.64039421e-01, -3.43156934e-01,  1.40396357e-02,\n",
       "         -3.35861206e-01, -2.64713407e-01, -3.75611544e-01,\n",
       "          4.83736157e-01, -3.36434484e-01,  2.85282969e-01,\n",
       "         -2.65330315e-01],\n",
       "        [ 3.83223772e-01, -4.81868029e-01, -2.34534264e-01,\n",
       "          3.75413775e-01,  1.28472686e-01, -3.74425173e-01,\n",
       "          1.70391798e-02, -4.17582750e-01, -3.69911075e-01,\n",
       "          2.66439915e-01],\n",
       "        [-5.88476658e-02, -1.57748818e-01, -3.35680604e-01,\n",
       "         -1.32947326e-01, -7.77705908e-02, -2.42291093e-01,\n",
       "          3.64388347e-01,  4.69096899e-02,  4.27551389e-01,\n",
       "          2.37341404e-01],\n",
       "        [-3.39520693e-01, -7.31303692e-02,  2.83777714e-03,\n",
       "          2.01643348e-01,  8.35298300e-02, -8.74150991e-02,\n",
       "          4.03000951e-01, -1.92032576e-01, -6.15764856e-02,\n",
       "         -1.82344317e-01],\n",
       "        [ 2.25806475e-01,  1.76604390e-01,  2.36814618e-01,\n",
       "         -4.75160480e-01,  3.47290039e-02,  3.50068212e-01,\n",
       "          3.00155401e-01,  2.41142392e-01, -3.61458063e-01,\n",
       "         -1.21563792e-01],\n",
       "        [ 2.02149630e-01, -3.89646411e-01,  3.28801274e-01,\n",
       "         -2.01119900e-01, -4.59475160e-01,  3.46223831e-01,\n",
       "          3.45862389e-01,  2.87659764e-01, -6.29751682e-02,\n",
       "         -2.56648779e-01],\n",
       "        [ 2.34248996e-01,  4.14479613e-01,  3.74686956e-01,\n",
       "          2.25343227e-01, -4.31266308e-01,  3.08996081e-01,\n",
       "         -6.16151094e-02,  4.60957885e-01, -3.75350952e-01,\n",
       "          5.90171814e-02],\n",
       "        [ 2.96637297e-01,  2.82806158e-02, -1.05241537e-01,\n",
       "          1.89067125e-01,  1.99402809e-01, -3.22113037e-01,\n",
       "          3.26826930e-01,  4.38980699e-01, -3.72630358e-02,\n",
       "          4.06619906e-01],\n",
       "        [-2.16789722e-01, -2.81957388e-01,  5.17290831e-02,\n",
       "          4.07483578e-01,  3.62786293e-01, -3.03495884e-01,\n",
       "         -3.00931931e-02, -2.19198465e-01,  4.76910233e-01,\n",
       "         -4.74954963e-01],\n",
       "        [ 2.22211957e-01, -2.95235872e-01, -4.15452003e-01,\n",
       "         -1.42568350e-01, -2.72090435e-01, -2.40175247e-01,\n",
       "          6.95765018e-02, -4.07085896e-01,  2.21221924e-01,\n",
       "         -3.74764204e-01],\n",
       "        [-3.34779024e-01, -3.11744452e-01,  4.19401407e-01,\n",
       "         -4.96028543e-01,  4.01655555e-01, -5.10108471e-03,\n",
       "          6.16019964e-02,  1.26421452e-02,  1.88517094e-01,\n",
       "         -3.92496467e-01],\n",
       "        [-4.71592426e-01, -8.26181173e-02,  4.44821954e-01,\n",
       "         -2.99631357e-01,  2.75834918e-01,  2.27122545e-01,\n",
       "          4.79371309e-01, -1.69943571e-02, -1.70297623e-02,\n",
       "          8.82233381e-02],\n",
       "        [ 4.27489281e-02, -8.77622366e-02, -3.90325785e-02,\n",
       "          4.51748133e-01, -1.73395991e-01, -1.95310712e-01,\n",
       "         -3.32780004e-01, -2.92898417e-01,  1.38450146e-01,\n",
       "         -3.68453741e-01],\n",
       "        [ 1.69628143e-01,  3.23447108e-01,  7.97840357e-02,\n",
       "         -2.51582861e-02,  4.39120650e-01,  2.43219972e-01,\n",
       "         -3.17221045e-01, -2.69566655e-01, -3.37835193e-01,\n",
       "         -2.53010154e-01],\n",
       "        [-4.08926487e-01, -2.81159282e-01,  1.21689916e-01,\n",
       "          4.73782778e-01, -3.54100108e-01,  1.48148537e-01,\n",
       "         -4.50776696e-01,  4.13382053e-02,  4.76229787e-01,\n",
       "          4.54493880e-01],\n",
       "        [ 4.96200442e-01, -2.04466820e-01, -1.51986480e-01,\n",
       "         -3.90425682e-01, -4.03781295e-01,  1.92076683e-01,\n",
       "         -1.16773248e-01, -3.28937292e-01,  1.10622644e-02,\n",
       "         -4.12777305e-01],\n",
       "        [-4.05439615e-01,  2.16948390e-01,  1.54561996e-02,\n",
       "          4.30866718e-01, -9.76991653e-03,  2.25630283e-01,\n",
       "          1.64903402e-01, -2.84065962e-01, -3.57787967e-01,\n",
       "         -3.74991417e-01],\n",
       "        [ 4.95432377e-01,  3.72507811e-01, -1.58948660e-01,\n",
       "          1.66000128e-01,  4.22478795e-01, -1.94834471e-01,\n",
       "         -5.04181385e-02, -1.41231418e-01,  1.53899670e-01,\n",
       "         -1.89993978e-01],\n",
       "        [ 2.81947374e-01, -6.15453720e-02, -7.51624107e-02,\n",
       "         -1.85958624e-01,  5.30810356e-02,  2.57097006e-01,\n",
       "         -4.91040587e-01,  8.04049969e-02, -2.10628033e-01,\n",
       "          1.05928421e-01],\n",
       "        [ 1.98093414e-01, -2.77615428e-01, -8.17872286e-02,\n",
       "          2.18330622e-01, -1.63304329e-01,  7.34863281e-02,\n",
       "          2.82716870e-01,  2.17462063e-01,  3.39459896e-01,\n",
       "          3.87557745e-02],\n",
       "        [-3.52208614e-02,  3.93513322e-01, -6.51519299e-02,\n",
       "         -9.05114412e-02, -3.96350026e-01, -1.56734347e-01,\n",
       "          3.38491082e-01,  1.42167330e-01,  2.35255480e-01,\n",
       "          4.36806083e-01],\n",
       "        [-2.78887749e-02, -4.09876585e-01, -4.11997080e-01,\n",
       "         -4.03636813e-01, -2.35636234e-02, -1.12332582e-01,\n",
       "          4.78848696e-01,  2.21280456e-01,  2.50356793e-01,\n",
       "         -5.20734787e-02],\n",
       "        [-5.90888262e-02, -4.97410655e-01,  4.66951728e-01,\n",
       "          1.23001456e-01,  3.00835729e-01,  1.27540112e-01,\n",
       "         -4.71464872e-01, -3.10256004e-01,  2.37028480e-01,\n",
       "         -3.38195324e-01],\n",
       "        [-2.22474337e-01, -4.38649535e-01, -3.68959546e-01,\n",
       "         -4.43104982e-01, -4.62562561e-01,  2.87100911e-01,\n",
       "          3.56475353e-01,  2.56739378e-01,  2.54568338e-01,\n",
       "          4.24853683e-01],\n",
       "        [-2.61939645e-01, -4.43840027e-03, -2.15517402e-01,\n",
       "          3.37390900e-02, -2.04378963e-01,  1.97044730e-01,\n",
       "         -1.83143139e-01, -4.64874506e-02,  1.79217935e-01,\n",
       "         -4.36053753e-01],\n",
       "        [ 3.34644794e-01,  2.48510003e-01,  3.11131597e-01,\n",
       "          3.10407996e-01, -4.72469330e-01,  4.69155431e-01,\n",
       "          3.59289646e-02,  4.70826626e-02,  2.34313846e-01,\n",
       "          4.09202814e-01],\n",
       "        [ 3.77850652e-01,  4.80840087e-01,  4.53716874e-01,\n",
       "          7.16936588e-03,  1.48486733e-01,  1.38371944e-01,\n",
       "          3.56050253e-01,  2.78037906e-01, -1.28767133e-01,\n",
       "         -1.71159506e-02],\n",
       "        [-2.49869704e-01, -3.16249728e-01, -3.48511934e-01,\n",
       "         -1.97852492e-01, -1.99488282e-01,  3.42247128e-01,\n",
       "          6.54928684e-02, -3.09844255e-01, -9.55482721e-02,\n",
       "          1.18301153e-01],\n",
       "        [ 3.73245120e-01, -3.12780142e-02,  1.08488679e-01,\n",
       "          4.43879604e-01,  4.19444203e-01,  2.22523689e-01,\n",
       "          2.35788703e-01, -3.21928859e-01,  4.73699212e-01,\n",
       "         -2.36015320e-02],\n",
       "        [-4.63494897e-01,  1.34264827e-01, -7.57204294e-02,\n",
       "         -2.11989880e-03,  1.63072467e-01,  2.44946480e-02,\n",
       "         -2.22171903e-01,  1.40961409e-02,  3.20614576e-02,\n",
       "         -2.96999454e-01],\n",
       "        [-1.19742632e-01, -7.93625116e-02,  1.84577227e-01,\n",
       "          4.92713332e-01, -1.20321393e-01,  1.35401964e-01,\n",
       "          2.70692229e-01,  1.52717590e-01, -3.27016711e-01,\n",
       "          1.94401622e-01],\n",
       "        [ 1.24153852e-01,  1.54049754e-01,  2.67129183e-01,\n",
       "          3.81231785e-01, -2.61995554e-01,  4.07552361e-01,\n",
       "         -3.49330068e-01, -4.24129486e-01,  2.60074139e-01,\n",
       "         -1.33799434e-01],\n",
       "        [-2.11083055e-01, -2.45822072e-01,  2.83615232e-01,\n",
       "          4.48188186e-01,  1.10197067e-02, -3.06919694e-01,\n",
       "         -1.50828958e-01,  3.66176367e-02,  5.96154928e-02,\n",
       "         -7.12605715e-02],\n",
       "        [ 4.54549432e-01, -1.53725147e-02, -8.63066912e-02,\n",
       "         -3.23977828e-01,  2.64582992e-01, -3.68606091e-01,\n",
       "          8.32551718e-02,  2.69659400e-01,  2.25266337e-01,\n",
       "          4.38409567e-01],\n",
       "        [-4.02468920e-01, -4.13694501e-01,  4.33691859e-01,\n",
       "         -2.16834307e-01, -3.53036761e-01,  4.71569300e-01,\n",
       "         -3.76438737e-01, -2.68390298e-01, -1.61316514e-01,\n",
       "         -2.45895147e-01],\n",
       "        [-2.36150622e-01,  2.74610519e-02,  2.10478663e-01,\n",
       "          1.89407349e-01, -8.03833008e-02, -3.09171677e-02,\n",
       "         -6.90869093e-02,  3.10420394e-01,  4.97380495e-01,\n",
       "         -1.50039434e-01],\n",
       "        [ 2.58932948e-01,  2.55580068e-01,  4.33536172e-01,\n",
       "          1.17794394e-01,  3.58517647e-01,  3.21933627e-01,\n",
       "         -1.22196674e-01, -2.19835758e-01, -3.86363745e-01,\n",
       "         -4.52049255e-01],\n",
       "        [ 4.86637235e-01,  2.07608223e-01,  1.70346498e-02,\n",
       "          2.75607705e-01, -3.23176980e-01, -3.50880742e-01,\n",
       "          1.96267009e-01, -2.13397264e-01,  4.87097025e-01,\n",
       "          2.91872740e-01],\n",
       "        [ 4.78034973e-01,  3.09728384e-01,  4.71200943e-01,\n",
       "          4.11421537e-01, -4.10566092e-01, -4.94696498e-01,\n",
       "         -3.99583936e-01, -1.42681479e-01,  2.77239203e-01,\n",
       "          7.39922523e-02],\n",
       "        [-6.82735443e-02, -4.70756412e-01, -3.28230143e-01,\n",
       "         -4.31089044e-01, -3.81456733e-01,  1.67582273e-01,\n",
       "          5.02159595e-02, -3.13081980e-01,  2.28169084e-01,\n",
       "         -1.13061666e-01],\n",
       "        [-4.06360626e-03,  3.42437148e-01,  2.50091076e-01,\n",
       "         -4.95488048e-01,  1.96584582e-01, -2.40696669e-02,\n",
       "          3.78383517e-01,  2.23440289e-01, -1.12069726e-01,\n",
       "         -4.62044477e-02],\n",
       "        [-4.36925888e-02, -1.08292460e-01,  6.83784485e-04,\n",
       "         -7.10315704e-02,  4.99850512e-01,  4.92739916e-01,\n",
       "          4.10845876e-01, -1.45585775e-01,  2.69999981e-01,\n",
       "         -1.41675115e-01],\n",
       "        [-1.85083508e-01,  1.25270486e-01,  1.90321684e-01,\n",
       "          3.86857867e-01, -6.50513172e-03, -3.21553111e-01,\n",
       "          5.24466038e-02, -3.04707289e-01, -5.30462265e-02,\n",
       "         -4.69765782e-01],\n",
       "        [ 7.17278719e-02,  4.21166301e-01, -4.82013822e-01,\n",
       "          1.83647990e-01, -1.69220328e-01,  4.54993129e-01,\n",
       "         -3.71959209e-02,  3.91045809e-01,  3.57666135e-01,\n",
       "         -1.06436491e-01],\n",
       "        [-5.18751144e-03,  2.61880517e-01,  1.43244267e-01,\n",
       "          2.18177080e-01,  3.44984055e-01,  5.71808815e-02,\n",
       "          2.64984369e-02,  1.07610703e-01, -3.46749425e-01,\n",
       "          3.90912294e-01]], dtype=float32),\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "test = Gen(4, 3)\n",
    "test.simulate()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
