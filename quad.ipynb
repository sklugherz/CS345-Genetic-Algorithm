{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "Typically a neural network will use a loss function and optimize the weights towards minimizing the value of the loss function. However, we wanted to explore the possibilties of using Genetic Algorithms to optimize weight vectors in a neural network for use in predictive models for real world application like the one used in the project, automated market trading. \n",
    "\n",
    "The baseline for this project is the same neural network model ran with the same initializer as our first generation of our Genetic Algorithm. The first generation of our Genetic Algorithm is essentially a unmodified neural network as the weights are defaulted to being random and we seeded our intializer for a form of consistency. \n",
    "\n",
    "We decided to use the first generation as our baseline because we wanted to see if our optimization technique could perform better than the default optimization of optimizing the MSE loss function.\n",
    "\n",
    "What we are attempting to substitute the baseline optimization for is a Genetic Algorithm. A Genetic Algorithm, or GA, is a optimization technique based on the principles of natural selection and genetics. GA's follow the same cycle of natural selection: An initial random population, Selection based on measured fitness, Survival and Termination, Reproduction based on the survived specimens, mutation and genetic crossover of parents to create children, and then the cycle continues.\n",
    "\n",
    "\n",
    "## Data Set\n",
    "\n",
    "The data was chosen purely for accesibility and abundancy which is why we went with data from the yfinance python library. We decided on using Apples market trading data because it's data was consistent within the last 5 years. The data extened further back than 5 years but we decided to cut it off after 5 years because of performance concerns. \n",
    "\n",
    "The yfinance library provided more datasets than just Apple's market trading data which meant we could use another companies dataset like AMD to test our optimization attempts. \n",
    "\n",
    "## Genetic Algorithm Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import yfinance as yf\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Class\n",
    "\n",
    "Simple class used to help process the data retrieved from yfinance library. We are defaulting to the Apple stock data by specifying the Apple ticker value of 'APPL'. Later we will use AMD stock data by specifying the AMD ticker value of 'AMD'. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Data:\n",
    "    def __init__(self):\n",
    "        self.data = yf.download('AAPL', period='5y', interval='1d')\n",
    "        self.current_index = 0\n",
    "\n",
    "    def get_current_price(self):\n",
    "        if self.current_index < len(self.data):\n",
    "            return self.data.iloc[self.current_index]['Close']\n",
    "        else:\n",
    "            return None\n",
    "\n",
    "    def get_tensor(self):\n",
    "        end_index = self.current_index + 1\n",
    "        start_index = max(0, end_index - 15)\n",
    "        return np.array(self.data.iloc[start_index:end_index])\n",
    "\n",
    "    def next(self):\n",
    "        if self.current_index < len(self.data) - 1:\n",
    "            self.current_index += 1\n",
    "        else:\n",
    "            self.current_index = 0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Brain Class\n",
    "\n",
    "The brain class is used to surround our neural network. We used defaulted parameters taken from the notebook on neural networks with keras because we wanted stable parameters to test against our Genetic Alorithm. It is a simple class that helps abstract pulling the weights from the neural network. Our prediction method is just to help us format the input and output. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Brain:\n",
    "    def __init__(self):\n",
    "        self.model = tf.keras.Sequential()\n",
    "        initializer = tf.keras.initializers.RandomUniform(minval=-.5, maxval=.5, seed=42)\n",
    "        # Define a model with 10 output neurons corresponding to binary classification tasks\n",
    "        self.model.add(tf.keras.layers.Dense(80, activation='relu', input_shape=(75,), kernel_initializer=initializer))\n",
    "        self.model.add(tf.keras.layers.Dense(10, activation='sigmoid', kernel_initializer=initializer))\n",
    "        self.model.compile(loss='mse', optimizer='adam', metrics=['accuracy', 'mse'])\n",
    "\n",
    "    def prediction(self, inputs):\n",
    "\n",
    "        inputs_np = np.array(inputs).reshape(1, -1)\n",
    "        pred = self.model.predict(inputs_np, verbose=0)\n",
    "\n",
    "        binary_outputs = (pred >= 0.5).astype(int)\n",
    "        \n",
    "        x, y = binary_outputs[0, 0], binary_outputs[0, 1]\n",
    "\n",
    "        binary_string = ''.join(str(bit) for bit in binary_outputs[0, 2:])\n",
    "        decimal_value = int(binary_string, 2)\n",
    "\n",
    "        z = decimal_value / 255\n",
    "\n",
    "        return [x, y, z]\n",
    "\n",
    "    def set_weights(self, weights):\n",
    "        self.model.set_weights(weights)\n",
    "\n",
    "    def get_weights(self):\n",
    "        return self.model.get_weights()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Agent Class\n",
    "\n",
    "This class is the host for the Brain. It holds all the logic for defining buy, sell, and hold vectors. It serves as the lowest level stock trading interface of our genetic algorithm. It holds a single instantiation of data from the Data class for all the agents to look at simultaneously.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Agent:\n",
    "\n",
    "    data = Data()\n",
    "    id = 0\n",
    "\n",
    "    def __init__(self):\n",
    "        self.id = Agent.id\n",
    "        Agent.id = Agent.id + 1\n",
    "        self.returns = 0\n",
    "        self.fitness = 0\n",
    "        self.input_dimension = 75\n",
    "        self.row_dimension = 5\n",
    "        self.row_data = Agent.data.get_tensor()[0] # numpy array of length 6\n",
    "\n",
    "        temp = []\n",
    "        for i in range(self.row_dimension):\n",
    "            temp.append(self.row_data[i])\n",
    "        for _ in range(self.input_dimension - self.row_dimension):\n",
    "            temp.append(0)\n",
    "\n",
    "        self.inputs = temp # python list of length 75\n",
    "        self.current_price = self.inputs[0]\n",
    "        self.brain = Brain()\n",
    "        self.predictions = self.brain.prediction(self.inputs) # returns [{0, 1}, {0, 1}, float_between(0, 1)]\n",
    "        self.active_trades = []\n",
    "\n",
    "    def __lt__(self, other):\n",
    "        if self.returns < other.returns:\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "\n",
    "    def make_trades(self):\n",
    "        if self.predictions[0] > 0.5:\n",
    "            if self.predictions[1] > 0.5:\n",
    "                self.buy(self.current_price * (1 + self.predictions[2]))\n",
    "            else:\n",
    "                self.sell(self.current_price * (1 - self.predictions[2]))\n",
    "\n",
    "    def buy(self, target):\n",
    "        if target > self.inputs[0] * 1.10:\n",
    "            self.fitness -= 10\n",
    "        else:\n",
    "            self.active_trades.append([target, 2*self.current_price - target, target - self.current_price, 1])\n",
    "\n",
    "    def sell(self, target):\n",
    "        if target < self.inputs[0] * 0.9:\n",
    "            self.fitness -= 10\n",
    "        else:\n",
    "            self.active_trades.append([target, 2*self.current_price - target, self.current_price - target, 0])\n",
    "\n",
    "    def close_trades(self):\n",
    "        to_keep = []\n",
    "        # print(f\"Active Trades: {self.active_trades}\")\n",
    "        for trade in self.active_trades:\n",
    "            if trade[3] == 1:\n",
    "                if trade[0] <= self.current_price:\n",
    "                    self.returns += trade[2]\n",
    "                elif trade[1] >= self.current_price:\n",
    "                    self.returns -= trade[2]\n",
    "                else:\n",
    "                    to_keep.append(trade)\n",
    "            else:\n",
    "                if trade[0] >= self.current_price:\n",
    "                    self.returns += trade[2]\n",
    "                elif trade[1] <= self.current_price:\n",
    "                    self.returns -= trade[2]\n",
    "                else:\n",
    "                    to_keep.append(trade)\n",
    "        self.active_trades = to_keep\n",
    "        # print(f\"Active Trades: {self.active_trades}\")\n",
    "\n",
    "    def force_close_trades(self):\n",
    "        clear = []\n",
    "        for trade in self.active_trades:\n",
    "            open = (trade[0] + trade[1]) / 2\n",
    "            if trade[3] == 1:\n",
    "                self.returns += self.current_price - open\n",
    "            else:\n",
    "                self.returns += open - self.current_price\n",
    "        self.active_trades = clear\n",
    "\n",
    "    def get_next_inputs(self):\n",
    "    # goes to next day, and appends the new data to inputs\n",
    "        self.data.next()\n",
    "        self.row_data = Agent.data.get_tensor()[0]\n",
    "        for i in range(self.row_dimension):\n",
    "            self.inputs.insert(0, self.row_data[i])\n",
    "            self.inputs.pop()\n",
    "        self.current_price = self.inputs[0]\n",
    "        self.predictions = self.brain.prediction(self.inputs)\n",
    "\n",
    "    def cycle(self):\n",
    "        self.close_trades()\n",
    "        self.make_trades()\n",
    "        self.get_next_inputs()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gen Class\n",
    "\n",
    "This class serves as the main driver for our Genetic Algorithm. Holds all of the logic perataining to the evolution driven design of a Genetic Algorithm. We designed it to take a dynamic population size and number of generations so we could test what we could get away with in terms of performance as our computation was a very limiting factor. Another peformance factor was the window of data we decided to pass in. In the simulate function, we run each agent for two months worth of data because we believe 60 days of trading is a good amount of data to balance the performance of our algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Gen:\n",
    "    def __init__(self, population_size, generations, mutation_rate=0.1):\n",
    "        self.population_size = population_size\n",
    "        self.generations = generations\n",
    "        self.mutation_rate = mutation_rate\n",
    "\n",
    "    def crossover(self, parent1, parent2):\n",
    "        child = Agent()\n",
    "        p1_weights = parent1.brain.get_weights()\n",
    "        p2_weights = parent2.brain.get_weights()\n",
    "        new_weights = []\n",
    "    \n",
    "        for p1_layer, p2_layer in zip(p1_weights, p2_weights):\n",
    "            if len(p1_layer.shape) == 1:  # This means the layer is one-dimensional (biases)\n",
    "                gene_cutoff = np.random.randint(0, p1_layer.size)\n",
    "                new_gene = np.concatenate([p1_layer[:gene_cutoff], p2_layer[gene_cutoff:]])\n",
    "            else:  # This means the layer is two-dimensional (weights)\n",
    "                gene_cutoff = np.random.randint(0, p1_layer.size)\n",
    "                new_gene = np.concatenate([p1_layer[:gene_cutoff], p2_layer[gene_cutoff:]])\n",
    "    \n",
    "            new_weights.append(new_gene)\n",
    "\n",
    "        child.brain.set_weights(new_weights)\n",
    "        return child\n",
    "    \n",
    "    def mutate(self, agent):\n",
    "        weights = agent.brain.get_weights()\n",
    "        mutated_weights = []\n",
    "        for weight in weights:\n",
    "            if np.random.rand() < self.mutation_rate:\n",
    "                mutation_matrix = np.random.uniform(-0.1, 0.1, weight.shape)\n",
    "                weight += mutation_matrix\n",
    "            mutated_weights.append(weight)\n",
    "        agent.brain.set_weights(mutated_weights)\n",
    "\n",
    "    def simulate(self):\n",
    "        NUM_MONTHS = 2\n",
    "        agents = []\n",
    "        for _ in range(self.population_size):\n",
    "            agent = Agent()\n",
    "            agents.append(agent)\n",
    "        for generation in range(self.generations):\n",
    "            for agent in agents:\n",
    "                for i in range(NUM_MONTHS * 30):\n",
    "                    agent.cycle()\n",
    "                agent.force_close_trades()\n",
    "                print(f\"Agent {agent.id}'s returns after {i + 1} cycles: {agent.returns:.2f}\")\n",
    "            ranked_agents = sorted(agents)\n",
    "            ranked_agents.reverse()\n",
    "            print(f\"=== Gen {generation} ===\\n Best: ${ranked_agents[0].returns:.2f}. Worst: ${ranked_agents[-1].returns:.2f}\")\n",
    "\n",
    "            elites = ranked_agents[:len(ranked_agents) // 2]\n",
    "            new_generation = []\n",
    "            for _ in range(int(self.population_size * 0.8)):\n",
    "                child = self.crossover(random.choice(elites), random.choice(elites))\n",
    "                self.mutate(child)\n",
    "                new_generation.append(child)\n",
    "            for i in range(int(self.population_size * 0.2)):\n",
    "                new_generation.append(elites[i])\n",
    "\n",
    "            agents = new_generation\n",
    "        return ranked_agents[0].brain.get_weights()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Output \n",
    "\n",
    "It is simple to run our code, simply call Gen() constructor with the population size and number of generations to run, then call simulate on the choses parameters. It also has an optional parameter for mutation rate.\n",
    "\n",
    "After it is run, it will return the weight vector of the agent that performed the best."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Agent.id = 0\n",
    "test = Gen(5, 4)\n",
    "rtn = test.simulate()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
